INICIO_SCRIPT
### Probabilidad.

#### Probabilidad fundamental.

Pregunta 1:

Considere un triángulo equilátero inscrito en un círculo. Suponga que se
escoge una cuerda del círculo. ¿Cuál es la probabilidad de que la cuerda
sea más larga que un lado del triángulo?

Pregunta 2.

Hay una cierta cantidad de líquido. Todo lo que sabemos sobre el líquido
es que está compuesto completamente de vino y agua, y que la proporción
de vino a agua está entre 1/3 y 3. ¿Cuál es la probabilidad de que la
proporción de vino a agua sea menor o igual a 2?

A la pregunta 1 se le conoce en probabilidad con el nombre de “la
paradoja de Bertrand”. Un tocayo francés de este anfitrión porque el
nombre propio de Bertrand es Joseph Louis.

A la pregunta 2 se le conoce con el nombre de “la paradoja del agua y el
vino de Ludwig Von Mises”, un judío nacido en el territorio de la actual
Ucrania que le tocó salir corriendo para Estados Unidos.

Estas dos preguntas en realidad no tienen nada de paradojas, simplemente
señalan la imposibilidad de aplicar genéricamente lo que se conoce en
probabilidad fundamental como “el principio de indiferencia”.

A la primera pregunta formulada en 1889 le han tratado de encontrar
soluciones, es decir le han tratado de hacer el quite, de varias
maneras. A la segunda pregunta simplemente no han podido darle
respuesta, es decir que no le han podido hacer el quite. El último
intento fue en el 2004.

Todos estos intentos fallan porque tratan de responder las preguntas
como tal y no el punto que pretenden establecer.

El punto es que NO EXISTE la supuesta “moneda justa”, una moneda 0.5 y
0.5 esa de la que ya se habló en este video. Toda moneda REAL esta
cargada hacia un lado y toda moneda que se puede describir con un
ALGORITMO es pseudo-aleatoria.

En el caso de las probabilidades fundamentales, esas que se basan en el
principio de indiferencia, dichas probabilidades dependen, ojo DEPENDEN,
de la forma de escoger eso que supuestamente tiene una distribución
aleatoria de forma “indiferente”, entre comillas.

Para realmente tratar de describir un comportamiento con probabilidades
fundamentales es necesario determinar, definir, establecer la función de
selección, esa que llaman aleatoria, esa que realmente nunca será
realmente aleatoria sino pseudo-aleatoria, es decir casi-aleatoria,
porque la tal “moneda justa” no existe.

En el caso de la probabilidad fundamental, para poder decir que ésta
describe el funcionamiento de un sistema, hay que definir la función
CHEPA, la función aleatoria. Se debe conocer el funcionamiento de la
función de selección. Así, dicha “indiferencia”, entre comillas, del
supuesto “principio de indiferencia”, de toda teoría de probabilidad
fundamental solo existe en los casos en que se conoce dicha función. No
se puede asumir que la conozco, hay que efectivamente definirla o
conocerla.

#### Probabilidad estadística.

Las teorías de probabilidad nacen con los juegos de cartas y de dados.
Buscan tratar de predecir un evento a partir de eventos pasados,
asignándole una valor a la posibilidad de que suceda.

En la probabilidad estadística, la probabilidad se entiende como lo que
realmente es: una simple frecuencia relativa. Tomo mi moneda real, la
tiro un millón de veces y cuento cuantas veces salió cara, cuantas veces
salió sello, y cuantas veces quedo parada en el borde. Luego, con esos
conteos calculo la frecuencia de cada posibilidad, y así determino la
probabilidad de que en mi siguiente lanzamiento salga cada posibilidad.

Así, ese tal “relativa” de toda frecuencia siempre está determinado por
el conocimiento PREVIO del problema. Se usa ese conocimiento para
establecer RELACIONES funcionales entre las variables del problema a
estudiar. Ese conocimiento previo esta definido en términos de funciones
matemáticas.

En la estadística se usa es el conocimiento parcial que se tiene del
funcionamiento del sistema para tratar de predecir un evento futuro. Se
asume, o se pretende, o efectivamente se desconoce, el funcionamiento
completo del sistema.

Este tipo de teorías se usan en todo tipo de sistemas donde solo se
tiene un conocimiento PARCIAL del sistema global, de ese que incluye
subsistemas que si conozco, y puedo controlar, y otros que no.

Cuando mi creación, esa parte del sistema que si puedo describir
determinísticamente, esa parte que si puedo controlar, tiene que
interactuar con lo que no conozco, busco tratar, ojo TRATAR, de predecir
como será esa interacción, de manera probabílistica. Por eso es que en
este tipo de creaciones, que interactúan con sistemas externos cuyo
funcionamiento se desconoce, dicha interacción a veces funciona y a
veces no.

#### Creaciones.

A nadie le sirve tener una probabilidad de que las partes de su creación
estén o no estén en el lugar donde deben estar, y a nadie le sirve tener
una probabilidad de que las partes de su creación tengan o no la
velocidad que deben tener para que la creación funcione.

A nadie le sirve que las partes de su maquinaria tal vez si estén donde
deben estar y tal vez si hagan lo que deben hacer. No se pueden
construir MAQUINAS en términos de lo que solo se conoce una probabilidad
de que sus partes SÍ estén, y SÍ se muevan, sí tengan la velocidad, el
momentum, o NO, que deben tener.

Las teorías de probabilidad son completamente inútiles para crear algo
porque no son sistemas deterministas. Solo sirven para tratar de
DESCRIBIR una CREACIÓN, una vez creada, como si no tuviera CREADOR, es
decir pretendiendo NO conocer el modelo determinista que describe dicha
creación. Sirven solamente para analizar una creación pretendiendo, o
asumiendo, que no se conoce su funcionamiento. Pretender usar una teoría
de probabilidad para explicar el funcionamiento fundamental de una
creación es simplemente negar su CREADOR.

#### Cuánticas.

Toda ideología cuántica es, en su aspecto matemático, una teoría de
probabilidad. Buscan calcular la probabilidad de que una, mal llamada,
“partícula elemental” tenga una posición, una velocidad, o un momentum
dado.

En el caso de las ideologías cuánticas fundamentales, el mismo problema
que presentan las teorías de probabilidad fundamental se aplica. Ese
supuesto “principio de indiferencia” es falso. La moneda “justa” no
existe. Hay que definir la función aleatoria en cada caso. No se puede
aplicar para tratar de explicar el funcionamiento fundamental de la
materia. Asumir el supuesto “principio de indiferencia”, entre comillas,
es un error fundamental desde el punto de vista estrictamente
matemático.

Y en el caso de las ideologías cuánticas que usan la probabilidad
estadística, el problema, por lo menos desde el punto de vista del
criterio de creatividad técnica, es que no son útiles. No califican como
ciencia porque no son deterministas, no sirven para construir un objeto
a partir de lo que estudian: supuestas partículas elementales.

La estadística sirve para analizar eventos de objetos creados, no para
crear los objetos. Para esto se necesitan modelos deterministas. Poder
predecir que van a hacer las piezas de mi creación en cada momento para
que mi creación haga lo que se supone que debe hacer.

#### Populares.

No se si le queda clara la idea pero lo que esto significa es que los
amantes de las populares ideologías cuánticas, esos que todavía usan
sistemas de estadística predictiva, o peor aun sistemas de probabilidad
basados en el supuesto “principio de indiferencia”, para tratar de
explicar, a punta de probabilidades, el comportamiento de unas supuestas
partículas elementales, esos amantes, lo que en realidad necesitan es
una explicación determinista sobre el comportamiento de las supuestas
partículas elementales para que de esa manera la explicación si sirva
para construir algo con las supuestas partículas elementales.

Tal vez deberían empezar a considerar que las supuestas partículas
elementales, ni son partículas, ni son elementales. Que realmente son
ondas electromagnéticas estacionarias que se desplazan en un MEDIO
tridimensional al cual se le ha negado su existencia desde finales del
siglo 19, cuando aparecen dos de las ideologías mas populares hoy día:
la cuántica en términos de probabilidad y la gravedad en términos de
curvatura.

En el siglo 19, a un “genio”, entre comillas, al que el Satán, el
enemigo, le metió en primera persona, la “genial idea”, entre comillas,
de ASUMIR que la velocidad de la luz era siempre la misma en un espacio
vacío, que aún está por encontrarse, y la postula como AXIOMA, o sea eso
que se ASUME y debe ser EVIDENTE para cualquiera, de su ideología, mal
llamada teoría, de la gravedad. Sin darse cuenta de que el supuesto
axioma, nada evidente para NADIE, la hace matemáticamente reducible al
ABSURDO.

Sin embargo, el MEDIO en el que se desplazan las ondas electromagnéticas
siempre ha estado ahí con el nombre de “campo electromagnético”, así no
lo quieran llamar MEDIO, como lo hacían en el siglo 19 antes de que
apareciera la absurda ideología de la gravedad gracias a su “evidente”,
entre comillas, “AXIOMA”, entre comillas, que ASUME que la velocidad de
la luz es siempre la misma en un espacio vacío que todavía está por
encontrarse.

Incluso algunos afirman que el ideólogo de la absurda ideología pensaba
que dicho MEDIO tenia que existir porque de otra manera la segunda
versión de su ABSURDA ideología, basada en el mismo AXIOMA, la volvería
ABSURDA. Al parecer el “genio”, entre comillas, nunca se dió cuenta que
su AXIOMA ya la hacía matemáticamente reducible al ABSURDO.

Triste ¿no?, pero así estamos, dos ideologías bastante populares, la una
científicamente absurda, la otra no solo eso sino también
matemáticamente absurda, y ambas que disque teorías CIENTÍFICAMENTE
comprobadas, lo dice la enciclopedia y lo cree la mayoría.


